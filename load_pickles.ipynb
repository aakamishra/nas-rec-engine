{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 59.62 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the system's virtual memory information\n",
    "virtual_memory = psutil.virtual_memory()\n",
    "\n",
    "# Get the available RAM in bytes\n",
    "available_ram = virtual_memory.available\n",
    "\n",
    "# Convert the available RAM to human-readable format\n",
    "available_ram_gb = available_ram / (1024 ** 3)  # Gigabytes\n",
    "\n",
    "# Print the available RAM\n",
    "print(f\"Available RAM: {available_ram_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 01:32:05.534324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 01:32:05.653230: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-10 01:32:06.450296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-05-10 01:32:06.450394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-05-10 01:32:06.450402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the pickle file\n",
    "pickle_file_path = '/home/ec2-user/nas-rec-engine/nas101graphs0-150000.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "# Now you can work with the loaded data\n",
    "# For example, print the loaded data\n",
    "print(len(loaded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302690\n"
     ]
    }
   ],
   "source": [
    "# Path to the pickle file\n",
    "pickle_file_path = '/home/ec2-user/nas-rec-engine/nas101graphs.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_data1 = pickle.load(file)\n",
    "\n",
    "# Now you can work with the loaded data\n",
    "# For example, print the loaded data\n",
    "print(len(loaded_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337190\n"
     ]
    }
   ],
   "source": [
    "print(len(loaded_data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  89%|########9 | 9492/10650 [01:14<00:08, 132.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  89%|########9 | 9506/10650 [01:14<00:15, 74.05it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  89%|########9 | 9517/10650 [01:14<00:19, 58.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  89%|########9 | 9526/10650 [01:15<00:22, 50.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|########9 | 9533/10650 [01:15<00:23, 47.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 11 unique features but batch size is 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|########9 | 9539/10650 [01:15<00:25, 43.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|########9 | 9563/10650 [01:16<00:30, 35.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|########9 | 9575/10650 [01:16<00:31, 33.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|######### | 9591/10650 [01:17<00:32, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  90%|######### | 9623/10650 [01:18<00:31, 32.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|######### | 9659/10650 [01:19<00:28, 34.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|######### | 9667/10650 [01:19<00:28, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|######### | 9683/10650 [01:19<00:27, 34.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9699/10650 [01:20<00:27, 34.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9707/10650 [01:20<00:27, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9715/10650 [01:20<00:27, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9723/10650 [01:20<00:28, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9731/10650 [01:21<00:29, 31.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 29 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  91%|#########1| 9739/10650 [01:21<00:28, 31.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9747/10650 [01:21<00:28, 31.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9755/10650 [01:21<00:28, 31.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9763/10650 [01:22<00:27, 31.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9771/10650 [01:22<00:25, 34.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9783/10650 [01:22<00:26, 32.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########1| 9791/10650 [01:23<00:27, 31.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 29 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########2| 9799/10650 [01:23<00:26, 32.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########2| 9819/10650 [01:23<00:24, 33.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 24 unique features but batch size is 32\n",
      "Collected 26 unique features but batch size is 32\n",
      "Collected 27 unique features but batch size is 32\n",
      "Collected 28 unique features but batch size is 32\n",
      "Collected 18 unique features but batch size is 20\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  92%|#########2| 9839/10650 [01:24<00:22, 36.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9852/10650 [01:24<00:21, 37.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 21 unique features but batch size is 32\n",
      "Collected 26 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9856/10650 [01:24<00:22, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 29 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 29 unique features but batch size is 32\n",
      "Collected 29 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9864/10650 [01:25<00:22, 34.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9872/10650 [01:25<00:22, 35.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9880/10650 [01:25<00:21, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########2| 9897/10650 [01:26<00:22, 32.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9913/10650 [01:26<00:23, 31.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9921/10650 [01:26<00:22, 32.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9929/10650 [01:27<00:22, 31.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9941/10650 [01:27<00:22, 31.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9953/10650 [01:27<00:22, 30.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  93%|#########3| 9957/10650 [01:28<00:22, 30.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########3| 9965/10650 [01:28<00:22, 30.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########3| 9973/10650 [01:28<00:21, 30.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########3| 9993/10650 [01:29<00:19, 33.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 29 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########3| 10002/10650 [01:29<00:17, 37.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 30 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########4| 10014/10650 [01:29<00:18, 33.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########4| 10026/10650 [01:30<00:19, 32.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########4| 10034/10650 [01:30<00:18, 32.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########4| 10042/10650 [01:30<00:18, 32.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  94%|#########4| 10062/10650 [01:31<00:18, 32.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########4| 10078/10650 [01:31<00:17, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########4| 10086/10650 [01:32<00:17, 32.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########4| 10106/10650 [01:32<00:16, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########4| 10114/10650 [01:32<00:16, 32.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 30 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########5| 10122/10650 [01:33<00:16, 32.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########5| 10138/10650 [01:33<00:16, 31.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########5| 10154/10650 [01:34<00:16, 30.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########5| 10158/10650 [01:34<00:16, 30.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  95%|#########5| 10170/10650 [01:34<00:15, 30.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  96%|#########5| 10178/10650 [01:34<00:15, 30.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n",
      "Collected 31 unique features but batch size is 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building batches:  96%|#########5| 10194/10650 [01:35<00:14, 31.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 31 unique features but batch size is 32\n",
      "Collected 14 unique features but batch size is 15\n",
      "Collected 28 unique features but batch size is 32\n",
      "Collected 28 unique features but batch size is 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomp_graph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_comp_graph_dataloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CGRegressDataLoader\n\u001b[0;32m----> 4\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mCGRegressDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_data1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nas-rec-engine/model_src/comp_graph/tf_comp_graph_dataloaders.py:49\u001b[0m, in \u001b[0;36mCGRegressDataLoader.__init__\u001b[0;34m(self, batch_size, data, verbose)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_batch_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 49\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_batches(data)\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches)\n",
      "File \u001b[0;32m~/nas-rec-engine/model_src/comp_graph/tf_comp_graph_dataloaders.py:99\u001b[0m, in \u001b[0;36mCGRegressDataLoader._build_batches\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     97\u001b[0m     batch_weighted_inds\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mLongTensor(weighted_node_inds)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m     98\u001b[0m     batch_weighted_shapes\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mFloatTensor(weighted_node_shapes)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m---> 99\u001b[0m     batch_weighted_kernels\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39;49mLongTensor(weighted_node_kernels)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m    100\u001b[0m     batch_weighted_bias\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mFloatTensor(weighted_node_bias)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m    101\u001b[0m batch_edge_list\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mLongTensor(edge_list))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from model_src.comp_graph.tf_comp_graph_dataloaders import CGRegressDataLoader\n",
    "\n",
    "\n",
    "loader = CGRegressDataLoader(32, loaded_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def split_train_val_data(data, val_ratio):\n",
    "    # Get the total number of elements in the data\n",
    "    total_elements = len(data)\n",
    "    \n",
    "    # Calculate the number of elements for the validation set\n",
    "    num_val_elements = int(total_elements * val_ratio)\n",
    "    \n",
    "    # Shuffle the indices of the data randomly\n",
    "    shuffled_indices = list(range(total_elements))\n",
    "    random.shuffle(shuffled_indices)\n",
    "    \n",
    "    # Split the indices into training and validation sets\n",
    "    val_indices = shuffled_indices[:num_val_elements]\n",
    "    train_indices = shuffled_indices[num_val_elements:]\n",
    "    \n",
    "    # Create the training and validation sets using the indices\n",
    "    train_set = [data[i] for i in train_indices]\n",
    "    val_set = [data[i] for i in val_indices]\n",
    "    \n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = split_train_val_data(loaded_data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(ComputeGraph[test](n_nodes: 28, n_edges: 36), (0.9215745329856873, 8555530)),\n",
       " (ComputeGraph[test](n_nodes: 24, n_edges: 30), (0.8815104365348816, 5878154)),\n",
       " (ComputeGraph[test](n_nodes: 23, n_edges: 29), (0.9243789911270142, 3729162)),\n",
       " (ComputeGraph[test](n_nodes: 23, n_edges: 28), (0.9080528616905212, 3729162)),\n",
       " (ComputeGraph[test](n_nodes: 21, n_edges: 26), (0.8962339758872986, 3292298)),\n",
       " (ComputeGraph[test](n_nodes: 19, n_edges: 23), (0.9017428159713745, 2479416)),\n",
       " (ComputeGraph[test](n_nodes: 22, n_edges: 27), (0.8937299847602844, 3468426)),\n",
       " (ComputeGraph[test](n_nodes: 26, n_edges: 33), (0.9189703464508057, 3078206)),\n",
       " (ComputeGraph[test](n_nodes: 28, n_edges: 36), (0.9247796535491943, 6315018)),\n",
       " (ComputeGraph[test](n_nodes: 26, n_edges: 33), (0.9199719429016113, 8118666))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd5eb279d10053843772e5b13836afa1489cd82e3492b360393a155ea89d875e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
