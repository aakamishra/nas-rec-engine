{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "from params import *\n",
    "import torch_geometric\n",
    "import utils.model_utils as m_util\n",
    "from model_src.demo_functions import *\n",
    "from utils.misc_utils import RunningStatMeter\n",
    "from model_src.model_helpers import BookKeeper\n",
    "from model_src.comp_graph.tf_comp_graph import OP2I\n",
    "from model_src.comp_graph.tf_comp_graph_models import make_cg_regressor, make_embedding_model\n",
    "from model_src.predictor.gpi_family_data_manager import FamilyDataManager\n",
    "from model_src.comp_graph.tf_comp_graph_dataloaders import CGRegressDataLoader\n",
    "from utils.model_utils import set_random_seed, device, add_weight_decay, get_activ_by_name\n",
    "from model_src.predictor.model_perf_predictor import train_predictor, run_predictor_demo, train_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_local_params(parser, ext_args=None):\n",
    "    parser.add_argument(\"-model_name\", required=False, type=str,\n",
    "                        default=\"CL_dropout_encoder_model\")\n",
    "    parser.add_argument(\"-family_train\", required=False, type=str,\n",
    "                        default=\"nb101\"\n",
    "                        )\n",
    "    parser.add_argument('-family_test', required=False, type=str,\n",
    "                        default=\"nb201c10#50\"\n",
    "                                \"+nb301#50\"\n",
    "                                \"+ofa_pn#50\"\n",
    "                                \"+ofa_mbv3#50\"\n",
    "                                \"+ofa_resnet#50\"\n",
    "                                \"+hiaml#50\"\n",
    "                                \"+inception#50\"\n",
    "                                \"+two_path#50\")\n",
    "    parser.add_argument(\"-dev_ratio\", required=False, type=float,\n",
    "                        default=0.1)\n",
    "    parser.add_argument(\"-test_ratio\", required=False, type=float,\n",
    "                        default=0.1)\n",
    "    parser.add_argument(\"-epochs\", required=False, type=int,\n",
    "                        default=60)\n",
    "    parser.add_argument(\"-fine_tune_epochs\", required=False, type=int,\n",
    "                        default=100)\n",
    "    parser.add_argument(\"-batch_size\", required=False, type=int,\n",
    "                        default=64)\n",
    "    parser.add_argument(\"-initial_lr\", required=False, type=float,\n",
    "                        default=0.0001)\n",
    "    parser.add_argument(\"-in_channels\", help=\"\", type=int,\n",
    "                        default=128, required=False)\n",
    "    parser.add_argument(\"-hidden_size\", help=\"\", type=int,\n",
    "                        default=128, required=False)\n",
    "    parser.add_argument(\"-out_channels\", help=\"\", type=int,\n",
    "                        default=128, required=False)\n",
    "    parser.add_argument(\"-num_layers\", help=\"\", type=int,\n",
    "                        default=6, required=False)\n",
    "    parser.add_argument(\"-dropout_prob\", help=\"\", type=float,\n",
    "                        default=0.4, required=False)\n",
    "    parser.add_argument(\"-aggr_method\", required=False, type=str,\n",
    "                        default=\"mean\")\n",
    "    parser.add_argument(\"-gnn_activ\", required=False, type=str,\n",
    "                        default=\"relu\")\n",
    "    parser.add_argument(\"-reg_activ\", required=False, type=str,\n",
    "                        default=None)\n",
    "    parser.add_argument('-gnn_type', required=False,\n",
    "                        default=\"GINConv\")\n",
    "    parser.add_argument(\"-normalize_HW_per_family\", required=False, action=\"store_true\",\n",
    "                        default=False)\n",
    "    parser.add_argument('-e_chk', type=str, default=None, required=False)\n",
    "    return parser.parse_args(ext_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_family_train_size_dict(args):\n",
    "    if args is None:\n",
    "        return {}\n",
    "    rv = {}\n",
    "    for arg in args:\n",
    "        if \"#\" in arg:\n",
    "            fam, size = arg.split(\"#\")\n",
    "        else:\n",
    "            fam = arg\n",
    "            size = 0\n",
    "        rv[fam] = int(float(size))\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_parser = prepare_global_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_fwd_func(_model, _batch):\n",
    "        # Define how a batch is handled by the model\n",
    "        regular_node_inds = _batch[DK_BATCH_CG_REGULAR_IDX]\n",
    "        regular_node_shapes = _batch[DK_BATCH_CG_REGULAR_SHAPES]\n",
    "        weighted_node_inds = _batch[DK_BATCH_CG_WEIGHTED_IDX]\n",
    "        weighted_node_shapes = _batch[DK_BATCH_CG_WEIGHTED_SHAPES]\n",
    "        weighted_node_kernels = _batch[DK_BATCH_CG_WEIGHTED_KERNELS]\n",
    "        weighted_node_bias = _batch[DK_BATCH_CG_WEIGHTED_BIAS]\n",
    "        edge_tsr_list = _batch[DK_BATCH_EDGE_TSR_LIST]\n",
    "        batch_last_node_idx_list = _batch[DK_BATCH_LAST_NODE_IDX_LIST]\n",
    "        return _model(regular_node_inds, regular_node_shapes,\n",
    "                      weighted_node_inds, weighted_node_shapes, weighted_node_kernels, weighted_node_bias,\n",
    "                      edge_tsr_list, batch_last_node_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_constructor(in_channels, out_channels):\n",
    "            nn = torch.nn.Sequential(torch.nn.Linear(in_channels, in_channels),\n",
    "                                     torch.nn.Linear(in_channels, out_channels),\n",
    "                                     )\n",
    "            return torch_geometric.nn.GINConv(nn=nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_embedding_model(n_unique_labels=len(OP2I().build_from_file()), out_embed_size=128,\n",
    "                              shape_embed_size=8, kernel_embed_size=8, n_unique_kernels=8, n_shape_vals=6,\n",
    "                              hidden_size=128, out_channels=128,\n",
    "                              gnn_constructor=gnn_constructor,\n",
    "                              gnn_activ=get_activ_by_name(\"relu\"), n_gnn_layers=6,\n",
    "                              dropout_prob=0.4, aggr_method=\"mean\",\n",
    "                              regressor_activ=get_activ_by_name(None)).to(device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import model_load\n",
    " \n",
    "\n",
    "checkpoint_file = \"/home/ec2-user/nas-rec-engine/saved_models/gpi_acc_predictor_CL_dropout_encoder_model_seed262_best.pt\"\n",
    "strict = True\n",
    "if os.path.isfile(checkpoint_file):\n",
    "    print(\"Found checkpoint: {}, loading\".format(checkpoint_file))\n",
    "    sd = model_load(checkpoint_file)\n",
    "    try:\n",
    "        model.load_state_dict(sd['model'], strict=strict)\n",
    "    except Exception:\n",
    "        # Handles the thop bug\n",
    "        state_dict = []\n",
    "        for n, p in sd['model'].items():\n",
    "            if \"total_ops\" not in n and \"total_params\" not in n:\n",
    "                state_dict.append((n, p))\n",
    "        model.load_state_dict(dict(state_dict), strict=strict)\n",
    "    print(\"Found best_eval_perf: {}, best_eval_iter: {}\".format(sd[CHKPT_BEST_EVAL_RESULT],\n",
    "                                                                    sd[CHKPT_BEST_EVAL_ITERATION]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd5eb279d10053843772e5b13836afa1489cd82e3492b360393a155ea89d875e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
